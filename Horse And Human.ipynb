{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zjeV6aa36KJO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5E5mFN06YU1",
    "outputId": "91f21187-c98d-488f-9d82-752524689dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1onaG42NZft3wCE1WH0GDEbUhu75fedP5\n",
      "From (redirected): https://drive.google.com/uc?id=1onaG42NZft3wCE1WH0GDEbUhu75fedP5&confirm=t&uuid=0dfa0c3f-cb5a-455e-96e3-a63ec0d79d6e\n",
      "To: /content/horse-or-human.zip\n",
      "100% 150M/150M [00:02<00:00, 58.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1onaG42NZft3wCE1WH0GDEbUhu75fedP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "spePwrCv6qGf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "local_zip = '/content/horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
    "zip_ref.extractall('./horse-or-human')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ss-eluYn7eyt"
   },
   "outputs": [],
   "source": [
    "train_hourse = os.path.join('./horse-or-human/horses')\n",
    "train_human = os.path.join('./horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SW3e9NwI8EHc",
    "outputId": "0587f70e-df9a-4d47-c7e9-1ba7eacca390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse01-6.png', 'horse03-7.png', 'horse36-3.png', 'horse49-5.png', 'horse27-7.png', 'horse03-3.png', 'horse09-6.png', 'horse43-4.png', 'horse47-5.png', 'horse01-2.png']\n",
      "['human13-07.png', 'human05-03.png', 'human17-17.png', 'human11-26.png', 'human14-16.png', 'human12-13.png', 'human10-16.png', 'human06-21.png', 'human05-02.png', 'human02-04.png']\n"
     ]
    }
   ],
   "source": [
    "train_horse_image = os.listdir(train_hourse)\n",
    "print(train_horse_image[:10])\n",
    "train_human_image = os.listdir(train_human)\n",
    "print(train_human_image[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfvyLYHF8h4p",
    "outputId": "163815ff-5760-463b-999a-d7ed76c51466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toatal horse images 500\n",
      "Toatal human images 527\n"
     ]
    }
   ],
   "source": [
    "print('Toatal horse images',len(os.listdir(train_hourse)))\n",
    "print('Toatal human images',len(os.listdir(train_human)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UXRmxtcs8_Us"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mping\n",
    "nrows = 4\n",
    "ncols= 4\n",
    "pic_index= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0KfHciT09fdt"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape= (300,300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jshFcqUjCjm0",
    "outputId": "638b5eaf-becf-492a-807a-48b97013aa3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 149, 149, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPooli  (None, 73, 73, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPooli  (None, 35, 35, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 16, 16, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1704097 (6.50 MB)\n",
      "Trainable params: 1704097 (6.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hAI_pYkBC817"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "II8b0BQSENW0",
    "outputId": "cd6d2aaa-0ae7-404d-dd9f-ba1f18ab8dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_data = ImageDataGenerator(rescale = 1 /255)\n",
    "train_gernator = train_data.flow_from_directory(\n",
    "    './horse-or-human/',\n",
    "    target_size = (300,300),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAjf1CstFyJF",
    "outputId": "017cb383-1579-430b-df71-65298dd87117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 19s 804ms/step - loss: 0.7542 - accuracy: 0.5695\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 7s 857ms/step - loss: 1.1416 - accuracy: 0.5539\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6019 - accuracy: 0.6251\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 8s 952ms/step - loss: 1.2920 - accuracy: 0.6407\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 8s 916ms/step - loss: 0.4333 - accuracy: 0.8643\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 7s 853ms/step - loss: 0.4420 - accuracy: 0.8554\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 8s 954ms/step - loss: 0.1786 - accuracy: 0.9333\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 8s 954ms/step - loss: 0.3118 - accuracy: 0.8832\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1619 - accuracy: 0.9365\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 7s 856ms/step - loss: 0.4018 - accuracy: 0.8220\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 7s 1s/step - loss: 0.2181 - accuracy: 0.9288\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 8s 944ms/step - loss: 0.1201 - accuracy: 0.9577\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 8s 951ms/step - loss: 0.0809 - accuracy: 0.9700\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 7s 889ms/step - loss: 0.0690 - accuracy: 0.9722\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 7s 852ms/step - loss: 0.5040 - accuracy: 0.8765\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gernator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=15,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "veDD6y_aGrJU",
    "outputId": "f79a30ca-681d-4407-ed03-7fae040e8642"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-49cacf90-2b4c-410f-8d96-21987705031f\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-49cacf90-2b4c-410f-8d96-21987705031f\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving download.jpg to download.jpg\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[0.]\n",
      "download.jpgIs A hourse\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    path = '/content/' + fn\n",
    "    img = image.load_img(path,target_size=(300,300))\n",
    "    x =image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images,batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0] > 0.5:\n",
    "        print(fn + 'Is A human')\n",
    "    else:\n",
    "        print(fn + 'Is A hourse' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iErcqaPKJr12"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
